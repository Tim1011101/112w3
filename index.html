<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>PDF Explorer -- Pages & Root (Vector Renderer)</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<style>
  :root { color-scheme: light dark; }
  body { margin: 0; padding: 1rem; font: 16px/1.5 system-ui, Segoe UI, Arial, sans-serif; background-color: #f9fafb; color: #111827; }
  @media (prefers-color-scheme: dark) {
    body { background-color: #111827; color: #e5e7eb; }
  }
  header { display: flex; flex-wrap: wrap; gap: .75rem; margin-bottom: 1rem; align-items: center; }
  label { display: flex; align-items: center; gap: .5rem; font-weight: 600; }
  input[type="file"], select, button {
    font-size: 1rem; padding: .35rem .6rem; border-radius: 0.375rem; border: 1px solid #d1d5db; background: #fff; color: #111827;
  }
  select { min-width: 16ch; }
  button { cursor: pointer; background-color: #3b82f6; color: white; border-color: #3b82f6; transition: background-color 0.2s; font-weight: 600; }
  button:hover { background-color: #2563eb; }
  button:disabled { opacity: .6; cursor: not-allowed; background-color: #9ca3af; border-color: #9ca3af; }
  @media (prefers-color-scheme: dark) {
    input[type="file"], select { background-color: #374151; color: #e5e7eb; border-color: #4b5563; }
    button { background-color: #3b82f6; border-color: #3b82f6; }
    button:hover { background-color: #2563eb; }
    button:disabled { background-color: #4b5563; border-color: #4b5563; }
  }

  #viewportWrapper {
    width: 100vw;
    height: 70vh;
    overflow: hidden;
    position: relative;
    border: 2px solid #666;
    background: #fff;
    margin-bottom: 10px;
  }
  @media (prefers-color-scheme: dark) {
    #viewportWrapper { background: #0b0b0b; border-color: #444; }
  }
  #outputContainer {
    position: absolute;
    transform-origin: top left;
  }
  .layer {
    position: absolute;
    top: 0; left: 0;
    width: 100%; height: 100%;
    pointer-events: none;
  }
  .layer svg {
    position: absolute;
    top: 0; left: 0;
    width: 100%; height: 100%;
  }
  .layer svg text {
    pointer-events: auto;
    user-select: text;
    cursor: text;
  }

  #out {
    white-space: pre-wrap;
    word-break: break-word;
    font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace;
    border: 1px solid #d1d5db;
    border-radius: .5rem;
    padding: 1rem;
    overflow: auto;
    max-height: 75vh;
    background: #ffffff;
    color: #111827;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
  }
  @media (prefers-color-scheme: dark) {
    #out { background: #1f2937; border-color: #4b5563; color: #d1d5db; }
  }

  a.ref { color: #2563eb; text-decoration: underline; cursor: pointer; font-weight: bold; }
  @media (prefers-color-scheme: dark) {
    a.ref { color: #60a5fa; }
  }
  .debug-info {
    background: #fef3c7;
    border: 1px solid #f59e0b;
    padding: 0.5rem;
    margin: 0.5rem 0;
    border-radius: 0.375rem;
    font-size: 0.875rem;
    color: #7c2d12;
  }
  @media (prefers-color-scheme: dark) {
    .debug-info { background: #451a03; border-color: #d97706; color: #fbbf24; }
  }
</style>
</head>
<body>
<header>
  <label>PDF file:
    <input type="file" id="file" accept=".pdf">
  </label>
  <label>Page:
    <select id="pageSel" disabled></select>
  </label>
  <button id="rootBtn" disabled>Show /Root</button>
  <button id="debugBtn">Debug Info</button>
</header>

<div id="viewportWrapper">
  <div id="outputContainer"></div>
</div>

<div id="out">Pick a PDF file…</div>
<div style="position:fixed; right:12px; top:12px; z-index:9999; display:flex; gap:6px;">
  <button onclick="fitPage()">Fit page</button>
  <button onclick="fitWidth()">Fit width</button>
  <button onclick="fitHeight()">Fit height</button>
  <button onclick="zoomTo(getPDFZoom().value ? getPDFZoom().value*1.1 : 1.1)">+</button>
  <button onclick="zoomTo(getPDFZoom().value ? getPDFZoom().value/1.1 : 0.9)">−</button>
</div>

<script src="https://cdn.jsdelivr.net/npm/fflate"></script>
<script>
function initPDFExplorer() {
  const $file = document.getElementById('file');
  const $pages = document.getElementById('pageSel');
  const $rootBtn = document.getElementById('rootBtn');
  const $debugBtn = document.getElementById('debugBtn');
  const $out = document.getElementById('out');

  const objects = new Map();
  const pages = [];
  const fontCache = new Map();
  let rootKey = '';
  let debugInfo = [];
  const xrefEntries = new Map();
  let fileBytes = null;
  let fileText = '';

  const LF = 10, CR = 13, SPACE = 32;
  const ENDOBJ_BYTES = new TextEncoder().encode("endobj");
  const STREAM_BYTES = new TextEncoder().encode("stream");
  const ENDSTREAM_BYTES = new TextEncoder().encode("endstream");

  function reset() {
    objects.clear(); pages.length = 0; fontCache.clear(); rootKey = ''; debugInfo = []; xrefEntries.clear();
    fileBytes = null; fileText = '';
    $pages.innerHTML = ''; $pages.disabled = true;
    $rootBtn.disabled = true; $out.textContent = 'Pick a PDF file...';
    document.getElementById('outputContainer').innerHTML = '';
  }

  function extractTopLevelDict(bodyStr) {
    const start = bodyStr.indexOf('<<');
    if (start === -1) return '';
    let nest = 1;
    for (let i = start + 2; i < bodyStr.length - 1; i++) {
      if (bodyStr[i] === '<' && bodyStr[i+1] === '<') { nest++; i++; }
      else if (bodyStr[i] === '>' && bodyStr[i+1] === '>') {
        nest--; i++;
        if (nest === 0) return bodyStr.substring(start, i + 1);
      }
    }
    return bodyStr.substring(start);
  }

  function store(num, gen, body) {
    const key = `${num} ${gen}`;
    if (objects.has(key)) return;
    const dict = extractTopLevelDict(body);
    objects.set(key, { num, gen, dict, raw: body, stream: '', decoded: '', streamError: '', streamInfo: '', processed: false });
  }

  function findKeywordBytes(data, keywordBytes, start = 0) {
    const searchEnd = data.length - keywordBytes.length;
    for (let i = start; i <= searchEnd; i++) {
      let ok = true;
      for (let j = 0; j < keywordBytes.length; j++) {
        if (data[i + j] !== keywordBytes[j]) { ok = false; break; }
      }
      if (ok) return i;
    }
    return -1;
  }

  function extractDictAndStreamBoundsRough(objectBytes, globalStartOffset) {
    if (!objectBytes || objectBytes.length === 0) return { dictStr: null, streamStartOffset: -1, streamEndOffset: -1 };
    let dictStart = -1;
    for (let i = 0; i < objectBytes.length - 1; i++) {
      if (objectBytes[i] === 60 && objectBytes[i + 1] === 60) { dictStart = i; break; }
    }
    if (dictStart === -1) return { dictStr: null, streamStartOffset: -1, streamEndOffset: -1 };
    let dictEnd = -1;
    let nestingLevel = 0;
    for (let i = dictStart + 2; i < objectBytes.length - 1; i++) {
      if (objectBytes[i] === 60 && objectBytes[i + 1] === 60) { nestingLevel++; i++; }
      else if (objectBytes[i] === 62 && objectBytes[i + 1] === 62) {
        if (nestingLevel === 0) { dictEnd = i + 2; break; }
        else { nestingLevel--; i++; }
      }
    }
    if (dictEnd === -1) return { dictStr: null, streamStartOffset: -1, streamEndOffset: -1 };
    const dictStr = new TextDecoder('latin1').decode(objectBytes.slice(dictStart, dictEnd));
    const streamKeywordOffsetRel = findKeywordBytes(objectBytes, STREAM_BYTES, dictEnd);
    if (streamKeywordOffsetRel === -1) return { dictStr, streamStartOffset: -1, streamEndOffset: -1 };
    let streamStartOffsetRel = streamKeywordOffsetRel + STREAM_BYTES.length;
    while (streamStartOffsetRel < objectBytes.length) {
      const byte = objectBytes[streamStartOffsetRel];
      if (byte === CR || byte === LF || byte === SPACE) streamStartOffsetRel++;
      else break;
    }
    if (streamStartOffsetRel >= objectBytes.length) return { dictStr, streamStartOffset: -1, streamEndOffset: -1 };
    const endStreamKeywordOffsetRel = findKeywordBytes(objectBytes, ENDSTREAM_BYTES, streamStartOffsetRel);
    if (endStreamKeywordOffsetRel === -1) return { dictStr, streamStartOffset: globalStartOffset + streamStartOffsetRel, streamEndOffset: -1 };
    let streamEndOffsetRel = endStreamKeywordOffsetRel;
    while (streamEndOffsetRel > streamStartOffsetRel) {
      const byte = objectBytes[streamEndOffsetRel - 1];
      if (byte === CR || byte === LF || byte === SPACE) streamEndOffsetRel--;
      else break;
    }
    return {
      dictStr,
      streamStartOffset: globalStartOffset + streamStartOffsetRel,
      streamEndOffset: globalStartOffset + streamEndOffsetRel
    };
  }

  function resolveIndirectLength(txt, objNum, genNum) {
    const re = new RegExp(`\\b${objNum}\\s+${genNum}\\s+obj\\b([\\s\\S]*?)endobj`, 'm');
    const m = txt.match(re);
    if (!m) return -1;
    const body = m[1].trim();
    const num = parseInt(body, 10);
    return isNaN(num) ? -1 : num;
  }

async function flateDecode(bytes) {
  // Instead of DecompressionStream, use fflate for better PDF compatibility
  try {
    const decodedBytes = fflate.unzlibSync(bytes);
    return decodedBytes;
  } catch (err) {
    throw new Error(`Flate decompression failed: ${err.message}`);
  }
}

  function parseFilters(dictStr) {
    // Returns array of filter names, e.g., ['FlateDecode'] or ['FlateDecode','Crypt']
    const single = dictStr.match(/\/Filter\s*\/([A-Za-z0-9]+)\b/);
    if (single) return [single[1]];
    const arr = dictStr.match(/\/Filter\s*\[\s*([^\]]+)\]/);
    if (!arr) return [];
    const names = [];
    const re = /\/([A-Za-z0-9]+)\b/g;
    let m;
    while ((m = re.exec(arr[1]))) names.push(m[1]);
    return names;
  }

async function extractAndDecodeStream(obj, bytes, txt) {
  const { raw } = obj;
  const si = raw.indexOf('stream');
  if (si === -1) {
    obj.streamError = 'No stream keyword found';
    return;
  }

  const objHeader = `${obj.num} ${obj.gen} obj`;
  const objStartOffset = txt.indexOf(objHeader);
  if (objStartOffset === -1) {
    obj.streamError = 'Could not find object start in file text.';
    return;
  }
  const objEndOffset = txt.indexOf('endobj', objStartOffset);
  const objBytes = bytes.slice(objStartOffset, objEndOffset + 6);

  const { dictStr, streamStartOffset, streamEndOffset } = extractDictAndStreamBoundsRough(objBytes, objStartOffset);
  if (!dictStr) {
    obj.streamError = 'Could not extract dictionary or stream boundaries.';
    return;
  }

  const flateFilter = /\/Filter\s*(?:\/FlateDecode|\[\s*\/FlateDecode\b)/.test(dictStr);
  obj.streamInfo = `Filter: ${flateFilter ? 'FlateDecode' : 'None'}`;

  const lengthMatch = dictStr.match(/\/Length\s*(?:(\d+)\s+(\d+)\s+R|(\d+))/);
  let officialLength = -1;
  if (lengthMatch) {
    if (lengthMatch[1] && lengthMatch[2]) {
      officialLength = resolveIndirectLength(txt, +lengthMatch[1], +lengthMatch[2]);
      obj.streamInfo += `, Length: Indirect -> ${officialLength}`;
    } else {
      officialLength = parseInt(lengthMatch[3], 10);
      obj.streamInfo += `, Length: Direct -> ${officialLength}`;
    }
  }

  if (streamStartOffset === -1) {
    obj.streamError = 'Could not determine stream start offset.';
    return;
  }
  const start = streamStartOffset;
  const end = officialLength >= 0 ? Math.min(start + officialLength, bytes.length) : streamEndOffset;
  if (!(end > start)) {
    obj.streamError = `Invalid stream bounds (start: ${start}, end: ${end}).`;
    return;
  }

  const streamBytes = bytes.slice(start, end);
  obj.stream = new TextDecoder('latin1').decode(streamBytes);

  if (flateFilter) {
    try {
      const decodedBytes = fflate.unzlibSync(streamBytes);
      obj.decoded = new TextDecoder('latin1').decode(decodedBytes);
      obj.streamInfo += `, Flate decompressed successfully (${decodedBytes.length} bytes)`;
    } catch (err) {
      obj.streamError = `Flate decompression failed: ${err.message}`;
    }
  } else {
    // If the stream is raw, just use it as is
    obj.decoded = obj.stream;
    obj.streamInfo += `, Raw stream used as is`;
  }
}


  function checkEncryption(txt) {
    return /\/Encrypt\b/.test(txt);
  }

  async function expandObjStm(obj) {
    if (!/\/ObjStm\b/.test(obj.dict || '')) return;
    if (!obj.decoded) { debugInfo.push(`[expandObjStm] No decoded stream for /ObjStm ${obj.num} ${obj.gen}`); return; }
    const N_match = obj.dict.match(/\/N\s+(\d+)/);
    const F_match = obj.dict.match(/\/First\s+(\d+)/);
    const N = N_match ? +N_match[1] : 0;
    const F = F_match ? +F_match[1] : 0;
    if (!N || !F) { debugInfo.push(`[expandObjStm] Missing /N or /First in ${obj.num} ${obj.gen}`); return; }

    const headerStr = obj.decoded.slice(0, F).trim();
    const header = headerStr.split(/\s+/).map(Number);
    if (header.length < N * 2) { debugInfo.push(`[expandObjStm] Header length mismatch in ${obj.num} ${obj.gen}`); return; }

    let extractedCount = 0;
    for (let i = 0; i < N; i++) {
      const num = header[2 * i];
      const off = header[2 * i + 1];
      const start = F + off;
      const end = (i === N - 1) ? obj.decoded.length : F + header[2 * (i + 1) + 1];
      if (isNaN(num) || isNaN(off) || start > obj.decoded.length || start > end) continue;
      const body = obj.decoded.slice(start, end).trim();
      if (body) { store(num, 0, body); extractedCount++; }
    }
    debugInfo.push(`[expandObjStm] Expanded /ObjStm ${obj.num} ${obj.gen}: extracted ${extractedCount} of ${N} objects`);
  }

async function processObjStmIfNeeded(objNum, gen) {
  const entry = xrefEntries.get(objNum);
  if (!entry || entry.type !== 'compressed') return;
  const objStmKey = `${entry.objStm} 0`;
  const objStm = objects.get(objStmKey);
  if (!objStm) { debugInfo.push(`[LazyLoad] /ObjStm ${objStmKey} not found for obj ${objNum} ${gen}`); return; }
  if (objStm.processed) return;

  debugInfo.push(`[LazyLoad] Decompressing /ObjStm ${objStmKey} for obj ${objNum} ${gen}`);
  await extractAndDecodeStream(objStm, fileBytes, fileText);
  objStm.processed = true;

  if (objStm.decoded) {
    debugInfo.push(`[LazyLoad] /ObjStm ${objStmKey} decoded, expanding objects.`);
    await expandObjStm(objStm);
  } else {
    debugInfo.push(`[LazyLoad] Failed to decode /ObjStm ${objStmKey}: ${objStm.streamError || 'No decoded stream'}`);
  }
}

  function readBytes(bytes, start, length) {
    let val = 0;
    for (let i = 0; i < length; i++) val = (val << 8) | bytes[start + i];
    return val;
  }

  function parseTraditionalXref(xrefText) {
    const lines = xrefText.split(/\r?\n/);
    let i = 0;
    while (i < lines.length) {
      const line = lines[i].trim();
      if (line === 'xref') { i++; continue; }
      const subsectionMatch = line.match(/^(\d+)\s+(\d+)$/);
      if (subsectionMatch) {
        const firstObj = parseInt(subsectionMatch[1], 10);
        const numObjs = parseInt(subsectionMatch[2], 10);
        for (let j = 0; j < numObjs; j++) {
          i++;
          const entryLine = lines[i]?.trim();
          if (!entryLine) continue;
          const entryMatch = entryLine.match(/^(\d{10}) (\d{5}) ([fn])$/);
          if (entryMatch) {
            const offset = parseInt(entryMatch[1], 10);
            const gen = parseInt(entryMatch[2], 10);
            const status = entryMatch[3];
            const objNum = firstObj + j;
            if (status === 'f') xrefEntries.set(objNum, { type: 'free', nextFree: offset, gen });
            else if (status === 'n') xrefEntries.set(objNum, { type: 'in-use', offset, gen });
          }
        }
      }
      i++;
    }
    debugInfo.push(`Parsed ${xrefEntries.size} entries from traditional xref table`);
  }

  function parseXrefStream(xrefStreamObj) {
    if (!xrefStreamObj.decoded) {
      debugInfo.push(`Cannot parse XRef stream ${xrefStreamObj.num} ${xrefStreamObj.gen}: not decoded.`);
      return;
    }
    const dict = xrefStreamObj.dict;
    const wMatch = dict.match(/\/W\s*\[\s*(\d+)\s+(\d+)\s+(\d+)\s*\]/);
    const indexMatch = dict.match(/\/Index\s*\[([^\]]*)\]/);
    const sizeMatch = dict.match(/\/Size\s+(\d+)/);
    if (!wMatch) { debugInfo.push(`XRef stream ${xrefStreamObj.num} ${xrefStreamObj.gen} missing /W field.`); return; }

    const W = wMatch.slice(1, 4).map(Number);
    const Index = indexMatch ? indexMatch[1].trim().split(/\s+/).map(Number).filter(n => !isNaN(n)) : [0, sizeMatch ? parseInt(sizeMatch[1]) : 0];
    const data = new Uint8Array(xrefStreamObj.decoded.length);
    for (let i = 0; i < xrefStreamObj.decoded.length; i++) data[i] = xrefStreamObj.decoded.charCodeAt(i);

    const [w0, w1, w2] = W;
    const entrySize = w0 + w1 + w2;
    let byteIdx = 0;

    for (let i = 0; i < Index.length; i += 2) {
      const startObj = Index[i];
      const count = Index[i + 1];
      for (let j = 0; j < count; j++) {
        if (byteIdx + entrySize > data.length) break;
        const type = w0 ? readBytes(data, byteIdx, w0) : 1;
        const field1 = readBytes(data, byteIdx + w0, w1);
        const field2 = readBytes(data, byteIdx + w0 + w1, w2);
        byteIdx += entrySize;
        const objNum = startObj + j;
        if (type === 0) xrefEntries.set(objNum, { type: 'free', nextFree: field1, gen: field2 });
        else if (type === 1) xrefEntries.set(objNum, { type: 'in-use', offset: field1, gen: field2 });
        else if (type === 2) xrefEntries.set(objNum, { type: 'compressed', objStm: field1, index: field2 });
      }
    }
    debugInfo.push(`Parsed ${xrefEntries.size} entries from XRef stream ${xrefStreamObj.num} ${xrefStreamObj.gen}`);
  }

  function extractFontDict(dictStr) {
    const fontMatch = dictStr.match(/\/Font\s*<<([\s\S]*?)>>/);
    if (!fontMatch) return null;
    const fontDictStr = fontMatch[1];
    let nesting = 0;
    let fontDictEnd = -1;
    for (let i = 0; i < fontDictStr.length - 1; i++) {
      if (fontDictStr[i] === '<' && fontDictStr[i + 1] === '<') {
        nesting++; i++;
      } else if (fontDictStr[i] === '>' && fontDictStr[i + 1] === '>') {
        nesting--;
        if (nesting === -1) {
          fontDictEnd = i + 2; break;
        }
        i++;
      }
    }
    if (fontDictEnd !== -1) {
      return fontDictStr.substring(0, fontDictEnd);
    }
    return fontDictStr;
  }

async function cacheFontsFromResources(resourcesDict, pageKey) {
  debugInfo.push(`[FontCache] Raw /Resources dictionary for page ${pageKey}: ${resourcesDict}`);

  // 1) Extract /Font dictionary (be tolerant of malformed delimiters)
  const fontDictMatch = resourcesDict.match(/\/Font\s*(<<[\s\S]*?>>|<\s*\d+\s+\d+\s+R\s*>+)/);
  if (!fontDictMatch) {
    debugInfo.push(`[FontCache] No /Font dictionary found in /Resources for page ${pageKey}`);
    return;
  }

  const fontDictStr = fontDictMatch[1] || "";
  debugInfo.push(`[FontCache] Raw /Font dictionary for page ${pageKey}: ${fontDictStr}`);

  // 2) Find all font entries inside the dictionary
  const fontEntries = fontDictStr.match(/\/[A-Za-z0-9\-\+]+\s+[^>\s]+/g) || [];
  if (fontEntries.length === 0) {
    debugInfo.push(`[FontCache] No font entries found in /Font dictionary for page ${pageKey}`);
    return;
  }
  debugInfo.push(`[FontCache] Found ${fontEntries.length} font entries in /Font dictionary for page ${pageKey}: ${fontEntries.join(', ')}`);

  // 3) Process each font entry
  for (let entry of fontEntries) {
    let fontKey = null;
    let fontBody = null;

    // --- Sanitize malformed stuff like "<4 0 R>>>" -> "4 0 R"
    const cleanEntry = entry.replace(/[<>]+/g, " ").replace(/\s+/g, " ").trim();

    // Match: /F4 4 0 R   OR   just 4 0 R
    const refMatch = cleanEntry.match(/\/?([A-Za-z0-9\-\+]+)?\s*(\d+)\s+(\d+)\s+R/);
    const inlineMatch = cleanEntry.match(/\/([A-Za-z0-9\-\+]+)\s*<<([\s\S]*?)>>/);

    if (refMatch) {
      fontKey = refMatch[1] || `F${refMatch[2]}`;
      const objNum = +refMatch[2];
      const gen = +refMatch[3];
      const fontObjKey = `${objNum} ${gen}`;
      await processObjStmIfNeeded(objNum, gen);
      const fontObj = objects.get(fontObjKey);
      if (!fontObj) {
        debugInfo.push(`[FontCache] Font object ${fontObjKey} not found for ${fontKey} in page ${pageKey}`);
        continue;
      }
      fontBody = fontObj.dict || '';

      // 🔍 Follow /FontDescriptor to check for embedded font program
      const descMatch = fontBody.match(/\/FontDescriptor\s+(\d+)\s+(\d+)\s+R/);
      if (descMatch) {
        const descKey = `${descMatch[1]} ${descMatch[2]}`;
        await processObjStmIfNeeded(+descMatch[1], +descMatch[2]);
        const descObj = objects.get(descKey);
        if (descObj) {
          const fontFileMatch = descObj.dict.match(/\/FontFile[123]?\s+(\d+)\s+(\d+)\s+R/);
          if (fontFileMatch) {
            const fileKey = `${fontFileMatch[1]} ${fontFileMatch[2]}`;
            await processObjStmIfNeeded(+fontFileMatch[1], +fontFileMatch[2]);
            const fileObj = objects.get(fileKey);
            if (fileObj && !fileObj.processed) {
              await extractAndDecodeStream(fileObj, fileBytes, fileText);
              fileObj.processed = true;
            }
            if (fileObj?.decoded) {
              debugInfo.push(`[FontCache] Embedded font extracted for ${fontKey}, ${fileObj.decoded.length} bytes`);
              fontCache.set(fontKey, {
                type: (fontBody.match(/\/Subtype\s*\/(\w+)/) || [])[1] || 'Unknown',
                name: (fontBody.match(/\/BaseFont\s*\/([^\s\/]+)/) || [])[1] || 'Unknown',
                encoding: (fontBody.match(/\/Encoding\s*\/([^\s\/]+)/) || [])[1] || 'StandardEncoding',
                ttf: fileObj.decoded,  // raw embedded font data
                extension: 'ttf'
              });
              continue; // skip normal set
            }
          }
        }
      }

    } else if (inlineMatch) {
      fontKey = inlineMatch[1];
      fontBody = inlineMatch[2];
      debugInfo.push(`[FontCache] Processing inline font ${fontKey} for page ${pageKey}: ${fontBody}`);
    } else {
      debugInfo.push(`[FontCache] Invalid font entry format for ${entry} in page ${pageKey}`);
      continue;
    }

    // 4) Fallback: record base info even if no embedded font
    const subtype = (fontBody.match(/\/Subtype\s*\/(\w+)/) || [])[1] || 'Unknown';
    const baseFont = (fontBody.match(/\/BaseFont\s*\/([^\s\/]+)/) || [])[1] || 'Unknown';
    const encoding = (fontBody.match(/\/Encoding\s*\/([^\s\/]+)/) || [])[1] || 'StandardEncoding';

    fontCache.set(fontKey, {
      type: subtype,
      name: baseFont,
      encoding: encoding,
      ttf: null,
      extension: null
    });
  }
}


  function collectIndirectObjects(txt) {
    const re = /(\d+)\s+(\d+)\s+obj([\s\S]*?)endobj/g;
    for (let m; (m = re.exec(txt));) {
      const [_, n, g, body] = m;
      store(+n, +g, body.trim());
    }
  }

  async function discoverRootAndXrefs(txt, bytes) {
    rootKey = '';
    const startxrefMatch = txt.match(/startxref\s*(\d+)\s*%%EOF/);
    if (startxrefMatch) {
      const startxrefOffset = parseInt(startxrefMatch[1], 10);
      const xrefSection = txt.substring(startxrefOffset);
      const objMatch = xrefSection.match(/^(\d+)\s+(\d+)\s+obj/);
      if (objMatch) {
        const objKey = `${objMatch[1]} ${objMatch[2]}`;
        const xrefStreamObj = objects.get(objKey);
        if (xrefStreamObj && /\/Type\s*\/XRef\b/.test(xrefStreamObj.dict || '')) {
          await extractAndDecodeStream(xrefStreamObj, bytes, txt);
          const rootMatch = xrefStreamObj.dict.match(/\/Root\s+(\d+)\s+(\d+)\s+R/);
          if (rootMatch) rootKey = `${rootMatch[1]} ${rootMatch[2]}`;
          parseXrefStream(xrefStreamObj);
        }
      } else if (xrefSection.startsWith('xref')) {
        const trailerMatch = xrefSection.match(/trailer[\s\r\n]*<<([\s\S]*?)>>/);
        if (trailerMatch) {
          const rootMatch = trailerMatch[1].match(/\/Root\s+(\d+)\s+(\d+)\s+R/);
          if (rootMatch) rootKey = `${rootMatch[1]} ${rootMatch[2]}`;
          parseTraditionalXref(xrefSection);
        }
      }
    }
    if (!rootKey) {
      const tr = /trailer[\s\r\n]*<<([\s\S]*?)>>/g;
      let m, lastTrailer = '';
      while (m = tr.exec(txt)) lastTrailer = m[1];
      if (lastTrailer) {
        const m2 = lastTrailer.match(/\/Root\s+(\d+)\s+(\d+)\s+R/);
        if (m2) rootKey = `${m2[1]} ${m2[2]}`;
      }
    }
    if (rootKey) {
      const [num, gen] = rootKey.split(' ').map(Number);
      await processObjStmIfNeeded(num, gen);
    }
  }

  async function collectPagesFromRoot(key, visited = new Set()) {
    if (visited.has(key)) return;
    visited.add(key);
    const [num, gen] = key.split(' ').map(Number);
    await processObjStmIfNeeded(num, gen);
    const obj = objects.get(key);
    if (!obj) {
      console.warn(`Object ${key} not found during traversal`);
      debugInfo.push(`[Traversal] Object ${key} not found during page tree traversal`);
      return;
    }
    const typeMatch = (obj.dict || '').match(/\/Type\s*\/(\w+)/);
    const type = typeMatch ? typeMatch[1] : null;

    if (type === 'Catalog') {
      const pagesRefMatch = (obj.dict || '').match(/\/Pages\s+(\d+)\s+(\d+)\s+R/);
      if (pagesRefMatch) {
        const pagesKey = `${pagesRefMatch[1]} ${pagesRefMatch[2]}`;
        debugInfo.push(`[Traversal] /Catalog ${key} -> /Pages ${pagesKey}`);
        await processObjStmIfNeeded(+pagesRefMatch[1], +pagesRefMatch[2]);
        await collectPagesFromRoot(pagesKey, visited);
      } else {
        debugInfo.push(`[Traversal] /Catalog ${key} has no /Pages reference`);
      }
      return;
    }

    if (type === 'Page') {
      pages.push(obj);
      const resourcesMatch = (obj.dict || '').match(/\/Resources\s*(?:(\d+)\s+(\d+)\s+R|<<([\s\S]*?)>>)/);
      if (resourcesMatch) {
        if (resourcesMatch[1] && resourcesMatch[2]) {
          const resourcesKey = `${resourcesMatch[1]} ${resourcesMatch[2]}`;
          await processObjStmIfNeeded(+resourcesMatch[1], +resourcesMatch[2]);
          const resourcesObj = objects.get(resourcesKey);
          if (resourcesObj) {
            await cacheFontsFromResources(resourcesObj.dict || '', key);
          } else {
            debugInfo.push(`[FontCache] Resources object ${resourcesKey} not found for page ${key}`);
          }
        } else if (resourcesMatch[3]) {
          await cacheFontsFromResources(resourcesMatch[0], key);
        }
      } else {
        debugInfo.push(`[FontCache] No /Resources dictionary found for page ${key}`);
      }
    } else if (type === 'Pages') {
      const kidsMatch = (obj.dict || '').match(/\/Kids\s*\[([\s\S]*?)\]/);
      if (kidsMatch) {
        const kids = kidsMatch[1].match(/(\d+)\s+(\d+)\s+R/g) || [];
        for (const kidRef of kids) {
          const kidMatch = kidRef.match(/(\d+)\s+(\d+)\s+R/);
          if (kidMatch) {
            const kidKey = `${kidMatch[1]} ${kidMatch[2]}`;
            const [kidNum, kidGen] = kidKey.split(' ').map(Number);
            await processObjStmIfNeeded(kidNum, kidGen);
            await collectPagesFromRoot(kidKey, visited);
          }
        }
      } else {
        debugInfo.push(`[Traversal] /Pages ${key} has no /Kids array`);
      }
    } else {
      debugInfo.push(`[Traversal] Object ${key} Type=${type || 'Unknown'} ignored in page-tree traversal`);
    }
  }

  async function collectPages() {
    for (const o of objects.values()) {
      if (/\/Type\s*\/Page\b/.test(o.dict || '')) {
        pages.push(o);
        const resourcesMatch = (o.dict || '').match(/\/Resources\s*(?:(\d+)\s+(\d+)\s+R|<<([\s\S]*?)>>)/);
        if (resourcesMatch) {
          if (resourcesMatch[1] && resourcesMatch[2]) {
            const resourcesKey = `${resourcesMatch[1]} ${resourcesMatch[2]}`;
            await processObjStmIfNeeded(+resourcesMatch[1], +resourcesMatch[2]);
            const resourcesObj = objects.get(resourcesKey);
            if (resourcesObj) {
              await cacheFontsFromResources(resourcesObj.dict || '', `${o.num} ${o.gen}`);
            } else {
              debugInfo.push(`[FontCache] Resources object ${resourcesKey} not found for page ${o.num} ${o.gen}`);
            }
          } else if (resourcesMatch[3]) {
            await cacheFontsFromResources(resourcesMatch[0], `${o.num} ${o.gen}`);
          }
        } else {
          debugInfo.push(`[FontCache] No /Resources dictionary found for page ${o.num} ${o.gen}`);
        }
      }
    }
  }

  async function getPageContent(obj) {
    const contentsMatch = (obj.dict || '').match(/\/Contents\s*(?:(\d+)\s+(\d+)\s+R|\[([\s\S]*?)\])/);
    let content = '';
    if (contentsMatch) {
      if (contentsMatch[1] && contentsMatch[2]) {
        const contentKey = `${contentsMatch[1]} ${contentsMatch[2]}`;
        await processObjStmIfNeeded(+contentsMatch[1], +contentsMatch[2]);
        const contentObj = objects.get(contentKey);
        if (contentObj && !contentObj.processed) {
          await extractAndDecodeStream(contentObj, fileBytes, fileText);
          contentObj.processed = true;
        }
        if (contentObj && contentObj.decoded) {
          content = contentObj.decoded.trim();
        }
      } else if (contentsMatch[3]) {
        const refs = contentsMatch[3].match(/(\d+)\s+(\d+)\s+R/g) || [];
        for (const ref of refs) {
          const refMatch = ref.match(/(\d+)\s+(\d+)\s+R/);
          if (refMatch) {
            const contentKey = `${refMatch[1]} ${refMatch[2]}`;
            await processObjStmIfNeeded(+refMatch[1], +refMatch[2]);
            const contentObj = objects.get(contentKey);
            if (contentObj && !contentObj.processed) {
              await extractAndDecodeStream(contentObj, fileBytes, fileText);
              contentObj.processed = true;
            }
            if (contentObj && contentObj.decoded) {
              content += contentObj.decoded.trim() + '\n';
            }
          }
        }
      }
    }
    return content;
  }

  function linkify(s) {
    return s.replace(/(\d+)\s+(\d+)\s+R/g, (m, n, g) => {
      const id = `${n} ${g}`;
      return `<a class="ref" data-obj="${id}" title="Click to view object ${id}">${m}</a>`;
    });
  }

async function show(key) {
  const [num, gen] = key.split(' ').map(Number);
  await processObjStmIfNeeded(num, gen);
  const o = objects.get(key);
  if (!o) {
    $out.textContent = `Object ${key} not found.`;
    document.getElementById('outputContainer').innerHTML = '';
    return;
  }
  if (o.raw.indexOf('stream') !== -1 && !o.processed) {
    await extractAndDecodeStream(o, fileBytes, fileText);
    o.processed = true;
  }
  let txt = `Object ${key} obj\n`;
  txt += linkify(o.dict || o.raw);
  const isPage = /\/Type\s*\/Page\b/.test(o.dict || '');
  if (isPage) {
    txt += `\n\n----- Fonts for Page ${key} -----\n`;
    if (fontCache.size === 0) {
      txt += 'No fonts cached for this page.\n';
    } else {
      for (const [fontKey, fontData] of fontCache) {
        let line = `${fontKey}: Type=${fontData.type}, Name=${fontData.name}, Encoding=${fontData.encoding}`;
        if (fontData.ttf) line += `, TTF Data=${fontData.ttf.byteLength} bytes, Extension=${fontData.extension}`;
        txt += line + '\n';
      }
    }
    const content = await getPageContent(o);
    if (content) {
      txt += `\n\n----- Content Stream -----\n${content}`;
      const mediaBoxMatch = (o.dict || '').match(/\/MediaBox\s*\[\s*(\d+\.?\d*)\s+(\d+\.?\d*)\s+(\d+\.?\d*)\s+(\d+\.?\d*)\s*\]/);
      const mediaBox = mediaBoxMatch ? mediaBoxMatch.slice(1, 5).map(Number) : [0, 0, 612, 792];
      const width = mediaBox[2] - mediaBox[0];
      const height = mediaBox[3] - mediaBox[1];
      const outCont = document.getElementById('outputContainer');
      const wrapper = document.getElementById('viewportWrapper');

      const wrapperWidth = wrapper.clientWidth;
      const wrapperHeight = wrapper.clientHeight;
      const scale = Math.min(wrapperWidth / width, wrapperHeight / height);

      outCont.style.width = `${width}px`;
      outCont.style.height = `${height}px`;
      outCont// REMOVED double scaling: .style.transform = `scale(${scale})`;

      outCont.innerHTML = '';
      if (typeof window.renderPage === 'function') {
        try {
          await window.renderPage({
            content,
            fontCache,
            width,
            height,
            xrefEntries,
            objects,
            fileBytes
          }, outCont, wrapper);
        } catch (err) {
          console.error(`[Render] Failed to render page ${key}: ${err.message}`);
          debugInfo.push(`[Render] Failed to render page ${key}: ${err.message}`);
          txt += `\n\n----- Render Error -----\nFailed to render page: ${err.message}`;
        }
      } else {
        console.error(`[Render] window.renderPage is not defined for page ${key}`);
        debugInfo.push(`[Render] window.renderPage is not defined for page ${key}`);
        txt += `\n\n----- Render Error -----\nRendering is not available (text-vector.js not loaded).`;
      }
    } else {
      txt += `\n\n----- Content Stream -----\nNo content stream found.`;
      document.getElementById('outputContainer').innerHTML = '';
    }
  }
  if (o.streamError) txt += `\n\n----- stream decode error -----\n${o.streamError}`;
  if (o.streamInfo) txt += `\n\n----- stream info -----\n${o.streamInfo}`;
  if (o.decoded && !isPage) txt += `\n\n----- decoded stream -----\n${o.decoded.trim()}`;
  else if (o.stream) txt += `\n\n----- raw stream (${o.stream.length} bytes) -----`;
  $out.innerHTML = '<pre>' + txt + '</pre>';
}


  function showDebugInfo() {
    let html = '<div class="debug-info"><h3>Debug Information</h3>';
    html += debugInfo.map(info => `<div>${info.replace(/</g, '&lt;')}</div>`).join('');
    html += '<h4>Objects Summary</h4>';
    const sortedObjects = [...objects.entries()].sort(([a], [b]) => (+a.split(' ')[0]) - (+b.split(' ')[0]));
    for (const [key, obj] of sortedObjects) {
      const hasStream = obj.stream ? ' [stream]' : '';
      const hasDecoded = obj.decoded ? ' [decoded]' : '';
      const hasError = obj.streamError ? ' [ERROR]' : '';
      const type = obj.dict ? (obj.dict.match(/\/Type\s*\/(\w+)/) || ['', 'Unknown'])[1] : 'No dict';
      html += `<div>Obj ${key}: Type=${type}${hasStream}${hasDecoded}${hasError}</div>`;
    }
    html += '<h4>XRef Entries</h4>';
    const objNums = Array.from(xrefEntries.keys()).sort((a, b) => a - b);
    for (const objNum of objNums) {
      const entry = xrefEntries.get(objNum);
      let desc = `Obj ${objNum}: `;
      if (entry.type === 'free') desc += `free (gen ${entry.gen})`;
      else if (entry.type === 'in-use') desc += `used at offset ${entry.offset} (gen ${entry.gen})`;
      else if (entry.type === 'compressed') desc += `compressed in ObjStm ${entry.objStm} at index ${entry.index}`;
      html += `<div>${desc}</div>`;
    }
    html += '<h4>Font Cache</h4>';
    if (fontCache.size === 0) {
      html += '<div>No fonts cached.</div>';
    } else {
      for (const [fontKey, fontData] of fontCache) {
        let desc = `${fontKey}: Type=${fontData.type}, Name=${fontData.name}, Encoding=${fontData.encoding}`;
        if (fontData.ttf) {
          desc += `, TTF Data=${fontData.ttf.byteLength} bytes, Extension=${fontData.extension}`;
        }
        html += `<div>${desc}</div>`;
      }
    }
    html += '</div>';
    $out.innerHTML = html;
  }

  $file.addEventListener('change', async e => {
    reset();
    const f = e.target.files[0]; if (!f) return;
    $out.textContent = 'Parsing…';
    const buf = await f.arrayBuffer();
    fileBytes = new Uint8Array(buf);
    fileText = new TextDecoder('latin1').decode(buf);
    console.clear();
    console.log("--- Starting PDF Parse ---");
    debugInfo = [`=== PDF Parse Debug Info ===`, `File size: ${buf.byteLength} bytes`];

    collectIndirectObjects(fileText);
    console.log(`[Step 1] Found ${objects.size} classic objects.`);
    debugInfo.push(`[Step 1] Found ${objects.size} classic objects.`);

    await discoverRootAndXrefs(fileText, fileBytes);
    console.log(`[Step 2] Parsed XRef, root key: ${rootKey || 'none'}.`);
    debugInfo.push(`[Step 2] Parsed XRef, root key: ${rootKey || 'none'}`);

    if (rootKey && objects.has(rootKey)) {
      console.log("[Step 3] Traversing page tree from /Root...");
      await collectPagesFromRoot(rootKey);
      console.log(`[Step 3] Found ${pages.length} pages via tree traversal.`);
      debugInfo.push(`[Step 3] Found ${pages.length} pages via tree traversal`);
    } else if (rootKey) {
      console.warn("[Step 3] Root object identified but not found in objects.");
      debugInfo.push(`[Step 3] WARNING: Root ${rootKey} identified but not found`);
    }

    if (!pages.length) {
      console.warn('[Step 4] No pages via /Root tree. Fallback scanning /Type /Page.');
      await collectPages();
      console.log(`[Step 4] Found ${pages.length} pages via fallback scan.`);
      debugInfo.push(`[Step 4] Found ${pages.length} pages via fallback scan`);
    }

    const isEncrypted = checkEncryption(fileText);
    if (isEncrypted) {
      debugInfo.push(`[Step 5] WARNING: PDF appears to be encrypted - streams cannot be decoded`);
      console.warn("[Step 5] PDF is encrypted");
      $out.textContent = 'PDF is encrypted. Stream decoding is not supported.';
      return;
    }

    console.log("--- Parse Complete ---");
    buildUI();
  });

  $pages.addEventListener('change', async () => {
    const id = $pages.value; if (id) await show(id);
  });

  $rootBtn.addEventListener('click', async () => {
    if (rootKey) await show(rootKey);
  });

  $debugBtn.addEventListener('click', () => {
    showDebugInfo();
  });

  document.getElementById('out').addEventListener('click', async e => {
    const anchor = e.target.closest('a.ref');
    if (anchor && anchor.dataset.obj) {
      await show(anchor.dataset.obj);
    }
  });

  function buildUI() {
    if (pages.length) {
      $pages.disabled = false;
      pages.sort((a, b) => a.num - b.num);
      pages.forEach((p, i) => {
        const opt = document.createElement('option');
        opt.value = `${p.num} ${p.gen}`;
        opt.textContent = `Page ${i + 1} (obj ${p.num} ${p.gen})`;
        $pages.appendChild(opt);
      });
    } else {
      $pages.disabled = true;
    }
    $rootBtn.disabled = !rootKey;
    (async () => {
      if (pages.length > 0) {
        await show(`${pages[0].num} ${pages[0].gen}`);
        $pages.value = `${pages[0].num} ${pages[0].gen}`;
      } else if (rootKey && objects.has(rootKey)) {
        await show(rootKey);
      } else if (rootKey) {
        $out.textContent = `Root object ${rootKey} was identified, but its content was not found. The PDF might be corrupted or unsupported.`;
      } else {
        $out.textContent = 'No /Page or /Root object could be found. The PDF may be encrypted or corrupted.';
      }
    })();
  }
}

window.addEventListener('load', initPDFExplorer);
</script>
<script>
(() => {
  const KEY = '__pdfFitSingleton__';
  if (window[KEY]) return;
  window[KEY] = true;

  const Z = {
    padding: 16,
    minScale: 0.05,
    maxScale: 20,
    wrapperId: 'viewportWrapper',
    containerId: 'outputContainer',
    pageW: null,
    pageH: null,
  };

  function clamp(n,a,b){ return Math.max(a, Math.min(b,n)); }
  function els(){ return {
    wrap: document.getElementById(Z.wrapperId),
    out:  document.getElementById(Z.containerId),
  }; }

  function getPageSize(out) {
    const w = Z.pageW || parseFloat(out.style.width)  || out.offsetWidth  || 1024;
    const h = Z.pageH || parseFloat(out.style.height) || out.offsetHeight || 1024;
    return { w, h };
  }

  function layout() {
    const { wrap, out } = els();
    if (!wrap || !out) return;

    const { w:pageW, h:pageH } = getPageSize(out);
    out.style.width  = pageW + 'px';
    out.style.height = pageH + 'px';

    const vw = wrap.clientWidth  - Z.padding*2;
    const vh = wrap.clientHeight - Z.padding*2;
    let S = Math.min(vw / pageW, vh / pageH);
    S = clamp(S, Z.minScale, Z.maxScale);

    const tx = Math.floor((wrap.clientWidth  - pageW * S) / 2);
    const ty = Math.floor((wrap.clientHeight - pageH * S) / 2);

    out.style.transformOrigin = 'left top';
    out// REMOVED double scaling: .style.transform = `translate(${tx}px, ${ty}px) scale(${S})`;
  }

  // expose manual hook
  window.fitPDFViewport = layout;

  // when a new doc/page starts, tell us its size
  window.onPDFPageStart = function(pageW, pageH) {
    if (typeof pageW === 'number' && typeof pageH === 'number') {
      Z.pageW = pageW;
      Z.pageH = pageH;
    }
    requestAnimationFrame(layout);
  };

  // hook into renderPage once
  const origRender = window.renderPage;
  if (typeof origRender === 'function') {
    window.renderPage = async function(...args) {
      const params = args[0] || {};
      // 👇 grab real width/height if renderer provides them
      const pw = params.pageWidth  || params.width;
      const ph = params.pageHeight || params.height;
      if (typeof pw === 'number' && typeof ph === 'number') {
        Z.pageW = pw;
        Z.pageH = ph;
      }
      const res = await origRender.apply(this, args);
      requestAnimationFrame(layout);
      return res;
    };
  }

  window.addEventListener('resize', () => requestAnimationFrame(layout));
})();
</script>

<script src="text-vector.js"></script>
<script src="image.js"></script>

<!-- Injected unified PDF viewport fitter and public zoom API -->
<script>
(() => {
  // Shared zoom state (single source of truth)
  const ZS = {
    mode: 'fit-page',  // 'fit-page' | 'fit-width' | 'fit-height' | 'custom'
    zoom: 1,
    min: 0.05,
    max: 20,
    padding: 16,
  };

  function clamp(n, a, b){ return Math.max(a, Math.min(b, n)); }

  // Keep original implementations if they exist
  const originalFit = window.fitPDFViewport;
  const originalOnStart = window.onPDFPageStart;

  // Provide default onPDFPageStart if none exists
  if (typeof window.onPDFPageStart !== 'function') {
    window.onPDFPageStart = function(pageW, pageH) {
      // no-op default
    };
  }

  // Wrap/replace fitPDFViewport to honor ZS
  window.fitPDFViewport = function fitPDFViewport() {
    const wrap = document.getElementById('viewportWrapper') || document.getElementById('viewport') || document.body;
    const out  = document.getElementById('outputContainer') || document.getElementById('output') || document.body;
    if (!wrap || !out) return;

    const pageW = parseFloat(out.style.width)  || out.offsetWidth  || 1024;
    const pageH = parseFloat(out.style.height) || out.offsetHeight || 1024;

    const vw = (wrap.clientWidth  || window.innerWidth)  - ZS.padding * 2;
    const vh = (wrap.clientHeight || window.innerHeight) - ZS.padding * 2;

    let S;
    if (ZS.mode === 'fit-width')       S = vw / pageW;
    else if (ZS.mode === 'fit-height') S = vh / pageH;
    else if (ZS.mode === 'custom')     S = ZS.zoom;
    else                               S = Math.min(vw / pageW, vh / pageH); // fit-page

    S = clamp(S, ZS.min, ZS.max);

    const tx = Math.floor(((wrap.clientWidth  || window.innerWidth)  - pageW * S) / 2);
    const ty = Math.floor(((wrap.clientHeight || window.innerHeight) - pageH * S) / 2);

    out.style.transformOrigin = 'left top';
    out.style.transform = `translate(${tx}px, ${ty}px) scale(${S})`;

    if (typeof originalFit === 'function') {
      try { originalFit(); } catch (e) { /* ignore */ }
    }
  };

  // Ensure that when a new page layout is known, we refit
  const _onStart = window.onPDFPageStart;
  window.onPDFPageStart = function(pageW, pageH) {
    try { if (typeof originalOnStart === 'function') originalOnStart(pageW, pageH); } catch(e){}
    try { if (typeof _onStart === 'function' && _onStart !== window.onPDFPageStart) _onStart(pageW, pageH); } catch(e){}
    requestAnimationFrame(window.fitPDFViewport);
  };

  // Public controls used by buttons
  window.fitPage    = () => { ZS.mode = 'fit-page';   window.fitPDFViewport(); };
  window.fitWidth   = () => { ZS.mode = 'fit-width';  window.fitPDFViewport(); };
  window.fitHeight  = () => { ZS.mode = 'fit-height'; window.fitPDFViewport(); };
  window.zoomTo     = (v) => { ZS.mode = 'custom'; ZS.zoom = clamp(Number(v)||1, ZS.min, ZS.max); window.fitPDFViewport(); };
  window.getPDFZoom = () => ({ mode: ZS.mode, value: ZS.mode === 'custom' ? ZS.zoom : null });

  // Keep things responsive
  window.addEventListener('resize', () => requestAnimationFrame(window.fitPDFViewport));

  // Auto-fit on DOM ready
  if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', () => requestAnimationFrame(window.fitPDFViewport));
  } else {
    requestAnimationFrame(window.fitPDFViewport);
  }
})();
</script>

<!-- Auto-fit on intrinsic page size changes (upload/render) -->
<script>
(() => {
  function scheduleRefits() {
    // burst refits to catch async layout/paint
    requestAnimationFrame(window.fitPDFViewport);
    setTimeout(window.fitPDFViewport, 30);
    setTimeout(window.fitPDFViewport, 120);
  }

  // Force default to fit-page at startup (overrides any previous custom)
  if (typeof window.fitPage === 'function') {
    try { window.fitPage(); } catch(e){}
  } else {
    // fallback: run the viewport fitter if available
    if (typeof window.fitPDFViewport === 'function') scheduleRefits();
  }

  // Refit whenever outputContainer's intrinsic size changes (e.g., new PDF page rendered)
  const out = document.getElementById('outputContainer') || document.getElementById('output');
  if (out && 'ResizeObserver' in window) {
    const ro = new ResizeObserver(() => {
      // Only auto-fit when we're in an auto mode (fit-page/fit-width/fit-height).
      // If user picked custom zoom, don't override.
      const z = (typeof window.getPDFZoom === 'function') ? window.getPDFZoom() : null;
      const autoMode = !z || z.mode === 'fit-page' || z.mode === 'fit-width' || z.mode === 'fit-height';
      if (autoMode && typeof window.fitPDFViewport === 'function') scheduleRefits();
    });
    ro.observe(out);
  }

  // Provide a global you can call after you finish loading a new file:
  //   window.onPDFFileLoaded()
  // It resets to "fit page" and refits.
  window.onPDFFileLoaded = function() {
    if (typeof window.fitPage === 'function') window.fitPage();
    scheduleRefits();
  };
})();
</script>

<!-- Aggressive auto-fit: better size detection + mutation observer -->
<script>
(() => {
  // Utility: clamp
  function clamp(n, a, b){ return Math.max(a, Math.min(b, n)); }

  // Robust page size detection
  function detectPageSize(out){
    // 1) Explicit width/height styles (from renderer)
    let w = parseFloat(out.style.width);
    let h = parseFloat(out.style.height);

    // 2) Prefer first child element natural size (canvas/svg/img)
    const c = out.firstElementChild;
    if ((!w || !h) && c){
      // Canvas
      if (c.tagName === 'CANVAS' && c.width && c.height){
        w = w || c.width;
        h = h || c.height;
      }
      // SVG
      if (c.tagName === 'SVG'){
        const vb = c.getAttribute('viewBox');
        if (vb){
          const parts = vb.trim().split(/[ ,]+/).map(Number);
          if (parts.length === 4){
            w = w || parts[2];
            h = h || parts[3];
          }
        }
        const sw = parseFloat(c.getAttribute('width'));
        const sh = parseFloat(c.getAttribute('height'));
        if (!w && sw) w = sw;
        if (!h && sh) h = sh;
      }
      // IMG
      if (c.tagName === 'IMG' && c.naturalWidth && c.naturalHeight){
        w = w || c.naturalWidth;
        h = h || c.naturalHeight;
      }
      // Fallback to offset if nothing else
      if ((!w || !h) && c.offsetWidth && c.offsetHeight){
        w = w || c.offsetWidth;
        h = h || c.offsetHeight;
      }
    }

    // 3) Fallback to scroll sizes (ignores transforms)
    if (!w || !h){
      const sw = out.scrollWidth;
      const sh = out.scrollHeight;
      if (sw && sh){
        w = w || sw;
        h = h || sh;
      }
    }

    // Sensible defaults as absolute last resort
    w = w || 1024;
    h = h || 1024;
    return { w, h };
  }

  // Override fitPDFViewport with more robust sizing
  const prevFit = window.fitPDFViewport;
  window.fitPDFViewport = function fitPDFViewport(){
    const wrap = document.getElementById('viewportWrapper') || document.getElementById('viewport') || document.body;
    const out  = document.getElementById('outputContainer') || document.getElementById('output') || document.body;
    if (!wrap || !out) return;

    const { w: pageW, h: pageH } = detectPageSize(out);

    // Read zoom state if provided by previous script
    let mode = 'fit-page', zoom = 1, min = 0.05, max = 20, pad = 16;
    if (typeof window.getPDFZoom === 'function'){
      const z = window.getPDFZoom();
      if (z && z.mode) mode = z.mode;
      if (z && z.value) zoom = Number(z.value) || 1;
    }
    // Try to peek at ZS if defined (not required)
    try {
      if (window.ZS) { min = window.ZS.min || min; max = window.ZS.max || max; pad = window.ZS.padding || pad; }
    } catch(e){}

    const vw = (wrap.clientWidth  || window.innerWidth)  - pad * 2;
    const vh = (wrap.clientHeight || window.innerHeight) - pad * 2;

    let S;
    if (mode === 'fit-width')       S = vw / pageW;
    else if (mode === 'fit-height') S = vh / pageH;
    else if (mode === 'custom')     S = zoom;
    else                            S = Math.min(vw / pageW, vh / pageH); // fit-page
    S = clamp(S, min, max);

    const tx = Math.floor(((wrap.clientWidth  || window.innerWidth)  - pageW * S) / 2);
    const ty = Math.floor(((wrap.clientHeight || window.innerHeight) - pageH * S) / 2);

    out.style.transformOrigin = 'left top';
    out.style.transform = `translate(${tx}px, ${ty}px) scale(${S})`;

    if (typeof prevFit === 'function'){
      try { prevFit(); } catch(e){}
    }
  };

  // Aggressive auto-fit strategy:
  function burstRefit(){
    requestAnimationFrame(window.fitPDFViewport);
    setTimeout(window.fitPDFViewport, 16);
    setTimeout(window.fitPDFViewport, 64);
    setTimeout(window.fitPDFViewport, 128);
    setTimeout(window.fitPDFViewport, 256);
  }

  // Always start in fit-page
  if (typeof window.fitPage === 'function') {
    try { window.fitPage(); } catch(e){}
  }
  burstRefit();

  // Observe #outputContainer for child changes and attribute tweaks
  const out = document.getElementById('outputContainer') || document.getElementById('output');
  if (out){
    const mo = new MutationObserver((muts) => {
      // Only auto-fit when using auto modes
      let mode = 'fit-page';
      if (typeof window.getPDFZoom === 'function'){
        const z = window.getPDFZoom();
        if (z && z.mode) mode = z.mode;
      }
      const autoMode = mode === 'fit-page' || mode === 'fit-width' || mode === 'fit-height';
      if (!autoMode) return;
      // If children added/removed or attributes changed, refit
      for (const m of muts){
        if (m.type === 'childList' || m.type === 'attributes'){
          burstRefit();
          break;
        }
      }
    });
    mo.observe(out, { childList: true, subtree: true, attributes: true });
  }

  // Also refit when the wrapper size changes
  const wrap = document.getElementById('viewportWrapper') || document.getElementById('viewport');
  if (wrap && 'ResizeObserver' in window){
    const ro = new ResizeObserver(() => burstRefit());
    ro.observe(wrap);
  } else {
    window.addEventListener('resize', burstRefit);
  }

  // Global hook to call after a file finishes loading
  window.onPDFFileLoaded = function(){
    if (typeof window.fitPage === 'function') window.fitPage();
    burstRefit();
  };
})();
</script>
</body>
</html>
